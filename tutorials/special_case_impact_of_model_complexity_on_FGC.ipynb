{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Case: Impact of Model Complexity on Forest-Guided Clustering\n",
    "\n",
    "üìö In this notebook, we explore how increasing the **complexity of a Random Forest model affects the interpretability** of its explanations using Forest-Guided Clustering (FGC). While model optimization typically focuses on improving predictive performance, using metrics such as accuracy or R¬≤, this often leads to highly complex models with deeply grown trees that closely fit the training data. Although such models may perform well on the training set, they are at risk of overfitting, capturing noise rather than meaningful patterns. This overfitting not only reduces generalization performance, but also impacts the quality of insights obtained from post-hoc explainability methods. FGC leverages the internal structure of Random Forests to uncover stable and interpretable subgroups in the data. However, if the forest becomes too complex, these discovered patterns may no longer reflect general behavior, but rather instance-specific artifacts.\n",
    "\n",
    "üì¶ **Installation:** To get started, you need to install the `fgclustering` package. Please follow the instructions on the [official installation guide](https://forest-guided-clustering.readthedocs.io/en/latest/_getting_started/installation.html).\n",
    "\n",
    "üöß **Note:** For a general introduction to FGC, please refer to our [Introduction Notebook](https://forest-guided-clustering.readthedocs.io/en/latest/_tutorials/introduction_to_FGC_use_cases.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the Forest-Guided Clustering package\n",
    "from fgclustering import forest_guided_clustering, DistanceRandomForestProximity, ClusteringKMedoids\n",
    "\n",
    "## Imports for datasets\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "## Additional imports for use-cases\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè† The California Housing Dataset\n",
    "\n",
    "To investigate how model complexity affects the interpretability of Forest-Guided Clustering (FGC), we will use the **California Housing dataset**. This dataset was also used in *Use Case 3*, please refer there for a full description. In this example, we focus on a subset of the data: the first 1,500 samples are used as the training set to fit a `RandomForestRegressor`. We vary the `max_depth` hyperparameter to evaluate different model complexities. This will help us understand how increasing the depth of the trees impacts both model performance and the quality of the explanations retrieved by FGC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3159e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_housing = fetch_california_housing(as_frame=True).frame\n",
    "\n",
    "data_housing_train = data_housing.iloc[:1500]\n",
    "X_housing_train = data_housing_train.loc[:, data_housing_train.columns != 'MedHouseVal']\n",
    "y_housing_train = data_housing_train.MedHouseVal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e3c57",
   "metadata": {},
   "source": [
    "## üå≤ Evaluating Model Complexity: Shallow vs. Deep Random Forests\n",
    "\n",
    "Below, we train two Random Forest models with different levels of complexity. The first is a **shallow model** with `max_depth=10`, meaning the maximum depth of any tree in the ensemble is limited to 10. The second is a **deep model** with `max_depth=50`, allowing much deeper trees and therefore greater model complexity. If we were to optimize based purely on performance metrics, we might prefer the deeper model as it achieves a slightly higher training score (0.96) compared to the shallow model‚Äôs score of 0.94. However, raw performance doesn't tell the full story. To evaluate interpretability and the stability of patterns captured by each model, we now apply **Forest-Guided Clustering (FGC)** to both trained models. This allows us to assess whether the discovered clusters reflect meaningful, generalizable structure or whether the model has simply overfit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2 score Shallow Model: 0.9391860496404276\n",
      "Train R^2 score Deep Model: 0.9624061659550253\n"
     ]
    }
   ],
   "source": [
    "rf_housing_shallow = RandomForestRegressor(max_depth=10, max_features='log2', max_samples=0.8, bootstrap=True, random_state=42)\n",
    "rf_housing_shallow.fit(X_housing_train, y_housing_train)\n",
    "\n",
    "print(f'Train R^2 score Shallow Model: {rf_housing_shallow.score(X_housing_train, y_housing_train)}')\n",
    "\n",
    "rf_housing_deep = RandomForestRegressor(max_depth=50, max_features='log2', max_samples=0.8, bootstrap=True, random_state=42)\n",
    "rf_housing_deep.fit(X_housing_train, y_housing_train)\n",
    "\n",
    "print(f'Train R^2 score Deep Model: {rf_housing_deep.score(X_housing_train, y_housing_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffb7c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a sample size of 66.66666666666666 % of the input data.\n",
      "Using range k = (2, 6) to optimize k.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing k: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:12<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal number of clusters k = 4\n",
      "\n",
      "Clustering Evaluation Summary:\n",
      " k    Score  Stable  Mean_JI                                                  Cluster_JI\n",
      " 2 0.988031    True    0.678                                        {1: 0.654, 2: 0.703}\n",
      " 3      NaN   False    0.513                              {1: 0.621, 2: 0.555, 3: 0.364}\n",
      " 4 0.754074    True    0.620                    {1: 0.711, 2: 0.491, 3: 0.612, 4: 0.665}\n",
      " 5      NaN   False    0.600          {1: 0.498, 2: 0.525, 3: 0.651, 4: 0.684, 5: 0.643}\n",
      " 6      NaN   False    0.537 {1: 0.611, 2: 0.379, 3: 0.61, 4: 0.577, 5: 0.678, 6: 0.367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fgc = forest_guided_clustering(\n",
    "    estimator=rf_housing_shallow, \n",
    "    X=data_housing_train, \n",
    "    y='MedHouseVal', \n",
    "    clustering_distance_metric=DistanceRandomForestProximity(), \n",
    "    clustering_strategy=ClusteringKMedoids(method=\"fasterpam\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b268470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a sample size of 66.66666666666666 % of the input data.\n",
      "Using range k = (2, 6) to optimize k.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing k: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:11<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustering Evaluation Summary:\n",
      " k Score  Stable  Mean_JI                                                   Cluster_JI\n",
      " 2  None   False    0.494                                         {1: 0.912, 2: 0.076}\n",
      " 3  None   False    0.320                               {1: 0.117, 2: 0.709, 3: 0.135}\n",
      " 4  None   False    0.227                     {1: 0.126, 2: 0.499, 3: 0.129, 4: 0.155}\n",
      " 5  None   False    0.218           {1: 0.483, 2: 0.131, 3: 0.158, 4: 0.166, 5: 0.153}\n",
      " 6  None   False    0.185 {1: 0.106, 2: 0.326, 3: 0.157, 4: 0.172, 5: 0.175, 6: 0.175}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/lisasousa/Desktop/fg-clustering/fgclustering/optimizer.py:116: UserWarning: No stable clusters were found for JI cutoff 0.6!\n",
      "  warnings.warn(f\"No stable clusters were found for JI cutoff {JI_discart_value}!\")\n"
     ]
    }
   ],
   "source": [
    "fgc = forest_guided_clustering(\n",
    "    estimator=rf_housing_deep, \n",
    "    X=data_housing_train, \n",
    "    y='MedHouseVal', \n",
    "    clustering_distance_metric=DistanceRandomForestProximity(), \n",
    "    clustering_strategy=ClusteringKMedoids(method=\"fasterpam\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5643c",
   "metadata": {},
   "source": [
    "## üèÅ Insights: Why Model Complexity Affects Interpretability\n",
    "\n",
    "As shown in the results above, Forest-Guided Clustering (FGC) fails to identify any stable clustering when applied to the **deep Random Forest model** (max\\_depth=50). This indicates that the model does not learn **generalizable patterns**, and instead captures noise of the training data that do not translate into coherent, robust groupings.\n",
    "\n",
    "But why does this happen, especially when the model performs well in terms of R¬≤?\n",
    "\n",
    "The key lies in understanding that **performance metrics alone do not guarantee interpretability**. When we optimize exclusively for predictive performance, we often end up with highly complex models. In this case, increasing the tree depth to 50 led to very finely partitioned decision trees, with many leaves containing just a handful of samples. Such deep splits are likely to reflect **noise** or overly specific characteristics of individual training samples rather than meaningful structure in the data. This lack of structure is clearly reflected in the **Jaccard Index (JI)**, which measures the **stability of clusters across bootstrap samples**. A low JI indicates that the clusters are not reproducible, i.e., the model segments the data differently each time, pointing to **fragile or non-generalizable splits**. In contrast, the **shallow model** (max\\_depth=10), which performs nearly as well in terms of R¬≤, yields a **stable clustering** with JI > 0.6 for *k = 2* and *k = 4*. This demonstrates that the clusters are both **coherent** and **stable**.\n",
    "\n",
    "The takeaway? If you plan to interpret a Random Forest model using FGC, it‚Äôs critical to **balance performance with interpretability**. Choosing a simpler model that avoids overfitting often leads to more trustworthy, insightful explanations‚Äîand stable, actionable clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fgc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
